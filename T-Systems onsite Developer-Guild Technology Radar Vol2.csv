name;ring;quadrant;isNew;description
Team cognitive load;Adopt;Techniques;FALSE;"<p>Team interaction is a key concept when redesigning an organization for business agility and speed. These interactions will be reflected in the software being built (see <a href=""https://www.thoughtworks.com/about-us/news/2021/latest-thoughtworks-technology-radar-proclaims---embrace-conway-"">Conway's Law</a>) and indicate how effectively teams can autonomously deliver value to their customers. Our advice is to be intentional about how teams are designed and how they interact. Because we believe that organizational design and team interactions evolve over time, we think it's particularly important to measure and keep track of the <strong>team cognitive load</strong>, which indicates how easy or difficult teams find building, testing and maintaining their services. We've been using a <a href=""https://github.com/TeamTopologies/Team-Cognitive-Load-Assessment"">template</a> to assess team cognitive load that is based on ideas by the authors of the <em><a href=""https://teamtopologies.com/book"">Team Topologies</a></em> book.</p>

<p>We continue to be impressed by the positive impact of applying this book's concepts when communicating to clients and redesigning organizations. The authors recommend a simple but powerful approach to organizational design, identifying just four types of teams and three modes of interaction; this helps reduce ambiguity within the organization and provides a common vocabulary for teams, stakeholders and leadership to describe and design a team's work. To implement an org design change, we design the ideal to-be team topologies structure, apply any technical/staffing constraints (i.e., not enough employees) and then end up with the final to-be structure. That allows us to better advise clients and anticipate whether we're indeed improving cognitive load by comparing the as-is/to-be team structures.</p>"
Threat modeling;Adopt;Techniques;FALSE;"<p>We continue to recommend that teams carry out <strong><a href=""https://www.owasp.org/index.php/Category:Threat_Modeling"">threat modeling</a></strong> — a set of techniques to help you identify and classify potential threats during the development process — but we want to emphasize that this is not a one-off activity only done at the start of projects; teams need to avoid the <a href=""/radar/techniques/security-sandwich"">security sandwich</a>. This is because throughout the lifetime of any software, new threats will emerge and existing ones will continue to evolve thanks to external events and ongoing changes to requirements and architecture. This means that threat modeling needs to be repeated periodically — the frequency of repetition will depend on the circumstances and will need to consider factors such as the cost of running the exercise and the potential risk to the business. When used in conjunction with other techniques, such as establishing cross-functional security requirements to address common risks in the project's technologies and using automated security scanners, threat modeling can be a powerful asset.</p>"
Fake SMTP server to test mail-sending;Trial;Techniques;TRUE;"<p>Using test email accounts or entire test SMTP (Single Mail Transfer Protocol) servers remains a common software testing practice. However, using a real server carries the risk that <a href=""https://www.usatoday.com/story/money/2021/06/18/hbo-max-integration-test-email-confusion/7744108002/"">test emails will be sent to real people</a> and often complicates automated integration testing. We've seen success using a <strong>fake SMTP server to test mail sending</strong>, which records a request to send an email without actually sending it. Multiple open-source tools exist in this space, including <a href=""https://github.com/gessnerfl/fake-smtp-server"">fake-smtp-server</a>, which renders emails in a web UI for visual testing, and <a href=""https://www.mbtest.org/"">mountebank</a>, which exposes the sent emails through a REST API for integration testing. We recommend exploring this technique to reduce risk and improve testing efficiency.</p>"
Incremental developer platform;Trial;Techniques;TRUE;"<p>We've been writing about developer platforms and how to build them in almost every edition of the Radar since 2017. In the meantime, the <em><a href=""https://teamtopologies.com/book"">Team Topologies</a></em> book has also done a great job of describing the ideal of a platform that supports developers with ""self-service APIs, tools, services and knowledge."" However, we often see teams shooting for too much of that platform vision too fast. Instead, building an <strong>incremental developer platform</strong> is key.</p>

<p><em>Team Topologies</em> recommends to always strive for what they call the ""Thinnest Viable Platform"" necessary at any given stage, where the first version could even be just a set of documentation on a wiki. The next increment could increase the service level by providing templates or allowing teams to create pull requests. Further increments could then introduce self-service APIs, but only if valuable. In short, even though we've cautioned against fully <a href=""/radar/techniques/ticket-driven-platform-operating-models"">ticket-driven platform operating models</a>, going from zero to self-service is the other extreme. Pace yourself, <a href=""/radar/techniques/applying-product-management-to-internal-platforms"">treat your platform as a product</a> and build it up incrementally.</p>"
CUPID;Assess;Techniques;FALSE;"<p>How do you approach writing good code? How do you judge if you've written good code? As software developers, we're always looking for catchy rules, principles and patterns that we can use to share a language and values with each other when it comes to writing simple, easy-to-change code.</p>

<p>Daniel Terhorst-North has recently made a new attempt at creating such a checklist for good code. He argues that instead of sticking to a set of rules like <a href=""https://en.wikipedia.org/wiki/SOLID"">SOLID</a>, using a set of properties to aim for is more generally applicable. He came up with what he calls the <strong><a href=""https://dannorth.net/2022/02/10/cupid-for-joyful-coding/"">CUPID</a></strong> properties to describe what we should strive for to achieve ""joyful"" code: Code should be composable, follow the Unix philosophy and be predictable, idiomatic and domain based.</p>"
GitHub push protection;Assess;Techniques;TRUE;"<p>The accidental publication of secrets seems to be a perennial issue with tools such as <a href=""/radar/tools/talisman"">Talisman</a> popping up to help with the problem. Before now, GitHub Enterprise Cloud users with an Advanced Security License could enable security scanning on their accounts, and any secrets (API keys, access tokens, credentials, etc.) that were accidentally committed and pushed would trigger an alert. <strong><a href=""https://docs.github.com/en/enterprise-cloud@latest/code-security/secret-scanning/protecting-pushes-with-secret-scanning"">GitHub push protection</a></strong> takes this one step further, and brings it one step earlier in the development workflow, by blocking changes from being pushed at all if secrets are detected. This needs to be configured for the organization and applies, of course, only to license holders, but additional protection from publishing secrets is to be welcomed.</p>"
Server-driven UI;Assess;Techniques;FALSE;"<p><strong>Server-driven UI</strong> continues to be a hot topic of discussion in mobile circles because it offers the potential for developers to take advantage of faster change cycles without falling foul of an app store's policies around revalidation of the mobile app itself. Server-driven UI separates the rendering into a generic container in the mobile app while the structure and data for each view is provided by the server. This means that changes that once required a round trip to an app store can now be accomplished via simple changes to the responses the server sends. While some very large mobile app teams have had great success with this technique, it also requires a substantial investment in building and maintaining a complex proprietary framework. Such an investment requires a compelling business case. Until the case is made, it might be best to proceed with caution; indeed, we've experienced some horrendous, overly configurable messes that didn't actually deliver on the promised benefits. But with the backing of behemoths such as Airbnb and Lyft, we may very well see some useful frameworks emerge that help tame the complexity. Watch this space.</p>"
"Satellite workers without ""remote native""";Hold;Techniques;TRUE;"<p>The term ""remote team setup"" does not just describe one setup; it encompasses multiple <a href=""https://martinfowler.com/articles/remote-or-co-located.html"">patterns and flavors</a>. And many teams have been changing patterns recently. They're coming out of the ""everybody always remote"" mode that was forced on them by a pandemic and moving into a pattern of (often rotating) satellite workers, where part of the team is co-located and part of the team is remote. We see many of them failing to properly consider what this means for their ways of working. <strong>Satellite workers without ""remote native""</strong> ways of working is a slip back into privileging co-located practices. In a setup with satellite workers, it's important to still <a href=""/radar/techniques/use-remote-native-processes-and-approaches"">use ""remote native"" processes and approaches by default</a>. For example, if the co-located part of the team joins a meeting together, they should still all be on their individual laptops to participate in digital collaboration or meeting chat. Teams need to be aware of the risk of excluding their satellite workers and creating silos and feelings of exclusion. If you know that you'll always have at least one satellite team member, the default ways of working should assume remoteness.</p>"
SPA by default;Hold;Techniques;FALSE;"<p>The prevalence of teams choosing a single-page application (SPA) when they need a website continues. We remain concerned that people aren't properly recognizing SPAs as an architectural style to begin with; instead they're immediately jumping into framework selection. SPAs incur complexity that simply doesn't exist with traditional server-based websites: issues such as search engine optimization, browser history management, web analytics and first page load time all need to be addressed. Proper analysis and consideration of the trade-offs is required to determine if that complexity is warranted for business or user experience reasons. Too often teams are skipping that trade-off analysis, blindly accepting the complexity of <strong>SPAs by default</strong> even when business needs don't justify it. We still see some developers who aren't aware of an alternative approach because they've spent their entire career in a framework like React. We believe that many websites will benefit from the simplicity of server-side logic, and we're encouraged by techniques like <a href=""/radar/techniques/hotwire"">Hotwire</a> that help close the gap on user experience.</p>"
Superficial cloud native;Hold;Techniques;TRUE;"<p>The term ""cloud native"" was originally used to describe architectures with characteristics that took maximum advantage of public cloud hosting. Examples include distributed architectures composed of many small, stateless and collaborating processes, and systems with high levels of automation for building, testing and deploying applications. However, we've noticed a growing trend toward <strong>superficial cloud native</strong> designs that simply use a lot of a cloud vendor's proprietary services and stop there without revisiting the fundamentally monolithic, brittle or toil-intensive nature of the application. It’s important to remember that serverless functions by themselves don't make an application more resilient or easier to maintain and that cloud native is really a matter of design rather than a set of implementation choices.</p>"
Backstage;Adopt;Platforms;FALSE;"<p>In an increasingly digital world, improving developer effectiveness in large organizations is often a core concern of senior leaders. We've seen enough value with developer portals in general and <strong><a href=""https://backstage.io/"">Backstage</a></strong> in particular that we're happy to recommend it in Adopt. Backstage is an open-source developer portal platform created by Spotify that improves discovery of software assets across the organization. It uses Markdown <a href=""https://backstage.io/docs/features/techdocs/techdocs-overview"">TechDocs</a> that live alongside the code for each service, which nicely balances the needs of centralized discovery with the need for distributed ownership of assets. Backstage supports software templates to accelerate new development and a plugin architecture that allows for extensibility and adaptability into an organization's infrastructure ecosystem. <a href=""https://backstage.io/docs/features/software-catalog/software-catalog-overview"">Backstage Service Catalog</a> uses YAML files to track ownership and metadata for all the software in an organization's ecosystem; it even lets you track third-party SaaS software, which usually requires tracking ownership.</p>"
AWS Database Migration Service;Trial;Platforms;TRUE;"<p>Many of our teams have successfully used <strong><a href=""https://aws.amazon.com/dms/"">AWS Database Migration Service</a></strong> (DMS) to migrate data to and from AWS. In one of our Digital Transformation engagements, we achieved nearly zero downtime cut-over to the new system as we migrated data from Microsoft SQL Server to an AWS Relational Database Service (RDS) PostgreSQL instance. Such transformations involve many moving parts that require planning and coordination across multidisciplinary teams, but for data migration we're quite happy with DMS. It automatically manages the deployment, management and monitoring of all required resources. Over the years DMS has matured to support several <a href=""https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.html"">source</a> and <a href=""https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.html"">target</a> databases, and we continue to like it.</p>"
Colima;Trial;Platforms;FALSE;"<p><strong><a href=""https://github.com/abiosoft/colima"">Colima</a></strong> is becoming a popular open alternative to Docker Desktop. It provisions the <a href=""/radar/platforms/docker"">Docker</a> container run time in a Lima VM, configures the Docker CLI on macOS and handles port-forwarding and volume mounts. Colima uses <a href=""https://containerd.io/"">containerd</a> as its run time, which is also the run time on most managed <a href=""/radar/platforms/kubernetes"">Kubernetes</a> services — improving the important dev-prod parity. With Colima you can easily use and test the latest features of containerd, such as lazy loading for container images. We've been having good results with Colima in our projects. When in the Kubernetes space, we also use <a href=""https://github.com/containerd/nerdctl"">nerdctl</a>, a Docker-compatible CLI for containerd. Since Kubernetes has deprecated Docker as container run time and most managed-services (EKS, GKE, etc) are following its lead, more people will be looking to containerd native tools, hence the importance of tools like nerdctl. In our opinion, Colima is realizing its strong potential and becoming a go-to option as an alternative to Docker Desktop.</p>"
DataHub;Trial;Platforms;FALSE;"<p>Since we first mentioned <a href=""/radar/techniques/data-discoverability"">data discoverability</a> in the Radar, LinkedIn has evolved <a href=""https://engineering.linkedin.com/blog/2016/03/open-sourcing-wherehows--a-data-discovery-and-lineage-portal"">WhereHows</a> to <strong><a href=""https://github.com/linkedin/datahub"">DataHub</a></strong>, the next generation platform that addresses data discoverability via an extensible metadata system. Instead of crawling and pulling metadata, DataHub adopts a push-based model where individual components of the data ecosystem publish metadata via an API or a stream to the central platform. This push-based integration shifts ownership from the central entity to individual teams, making them accountable for their metadata. As a result, we've used DataHub successfully as an organization-wide metadata repository and entry point for multiple autonomously maintained data products. When taking this approach, be sure to keep it lightweight and avoid the slippery slope leading to centralized control over a shared resource.</p>"
DataOps.live;Trial;Platforms;TRUE;"<p><strong><a href=""https://www.dataops.live/"">DataOps.live</a></strong> is a data platform that automates environments in <a href=""/radar/platforms/snowflake"">Snowflake</a>. Inspired by <a href=""/radar/techniques/devops"">DevOps</a> practices, DataOps.live lets you treat the data platform like any other web platform by embracing continuous integration and continuous delivery (CI/CD), automated testing, observability and code management. You can roll back changes immediately without impacting the data or recover from complete failures and rebuild a fresh Snowflake tenant in minutes or hours instead of days. Our teams had good experiences with DataOps.live, because it allowed us to iterate quickly when building data products on top of Snowflake.</p>"
Teleport;Assess;Platforms;FALSE;"<p><strong><a href=""https://gravitational.com/teleport/"">Teleport</a></strong> is a tool for <a href=""/radar/techniques/zero-trust-architecture"">zero trust</a> network access to infrastructure. Traditional setups require complex policies or jump servers to restrict access to critical resources. Teleport, however, simplifies this with a unified access plane and with fine-grained authorization controls that replace jump servers, VPNs or shared credentials. Implemented as a single binary with out-of-the-box support for several protocols (including SSH, RDP, <a href=""/radar/platforms/kubernetes"">Kubernetes</a> API, MySQL, <a href=""/radar/platforms/mongodb"">MongoDB</a> and PostgreSQL wire protocols), Teleport makes it easy to set up and manage secured access across Linux, Windows or Kubernetes environments. Since we first mentioned it in the Radar, a few teams have used Teleport and our overall positive experience prompted us to highlight it.</p>"
GCP Vertex AI;Assess;Platforms;TRUE;"<p><strong><a href=""https://cloud.google.com/vertex-ai"">GCP Vertex AI</a></strong> is a unified artificial intelligence platform that allows teams to build, deploy and scale machine-learning (ML) models. Vertex AI includes pretrained models, which can be used directly, fine-tuned or combined with <a href=""/radar/techniques/automated-machine-learning-automl"">AutoML</a>, as well as infrastructure such as feature stores and pipelines for ML models. We like Vertex AI's integrated capabilities, which help to make it feel like a coherent AI platform.</p>"
k6;Adopt;Tools;FALSE;"<p>Since we first mentioned it in the Radar, <a href=""https://k6.io/""><strong>k6</strong></a> has become a go-to tool for performance testing. We continue to be fans of how easy it is to write JavaScript code for tests, but k6 also has a low-code <a href=""https://k6.io/docs/test-authoring/test-builder"">test builder</a> to make playing with the tool even easier. The documentation shows how easy it is to add performance testing to a pipeline across <a href=""https://k6.io/docs/integrations/#continuous-integration-and-continuous-delivery"">multiple CI/CD tools</a>. Our teams find it easy to integrate <a href=""https://k6.io/docs/integrations/#result-store-and-visualization"">visualization tools</a> like <a href=""/radar/tools/grafana"">Grafana</a> and New Relic, which help them tune both infrastructure and applications. The developer friendliness and ecosystem make k6 a compelling option for investigating a system's behavior under heavy load.</p>"
Apache Superset;Trial;Tools;FALSE;"<p><strong><a href=""https://superset.apache.org/"">Apache Superset</a></strong> is a great business intelligence (BI) tool for data exploration and visualization to work with large data lake and data warehouse setups. It supports several <a href=""https://superset.apache.org/docs/databases/installing-database-drivers"">data sources</a> — including AWS Redshift, <a href=""/radar/platforms/bigquery"">BigQuery</a>, Azure MS SQL, <a href=""/radar/platforms/snowflake"">Snowflake</a> and <a href=""/radar/platforms/clickhouse"">ClickHouse</a>. Moreover, you don't have to be a data engineer to use it; it's meant to benefit all engineers exploring data in their everyday work. For demanding use cases, we found it easy to scale Superset by deploying it in a <a href=""/radar/platforms/kubernetes"">Kubernetes</a> cluster. Since we last talked about it in the Radar, Superset has graduated as an Apache product, and we've seen great success in several projects.</p>"
Hadolint;Assess;Tools;TRUE;"<p>We like spreading the word about linting tools that actually help you find issues rather than just shortcut style disputes in the team. <strong><a href=""https://github.com/hadolint/hadolint"">Hadolint</a></strong> is one of those tools — it helps find common issues in Dockerfiles. We find it to be fast, accurate and with good documentation. It explains both how to fix an issue and why it's an issue in the first place, thus nudging Dockerfile authors toward good practices. Incidentally, Hadolint is built on top of <a href=""/radar/tools/shellcheck"">ShellCheck</a>, which we recommend in its own right for checking your shell scripts.</p>"
Kaniko;Trial;Tools;TRUE;"<p>Most of today's CI/CD pipeline tools and platforms are built on containers as runtimes. Many of our teams are using <strong><a href=""https://github.com/GoogleContainerTools/kaniko"">Kaniko</a></strong> to build container images from within those container-based pipelines. This comes as part of a trend away from <a href=""/radar/platforms/docker"">Docker</a> as the de facto standard for container runtimes. With Kaniko, you can build your images without using a Docker daemon. This helps avoid the security issue of Docker's ""privileged"" mode, which would be necessary for any ""Docker-in-Docker"" activity. Moreover, you don't have to assume that your pipeline has access to a Docker daemon in the first place, which cannot be taken for granted anymore and often requires extra configuration.</p>"
Spectral;Assess;Tools;FALSE;"<p><strong><a href=""https://stoplight.io/open-source/spectral/"">Spectral</a></strong> is a JSON/YAML linter with an emphasis on OpenAPI and AsyncAPI specifications. It ships with a comprehensive set of out-of-the-box rules for these specs that can save developers headaches when designing and implementing APIs or event-driven collaboration. These rules check for proper API parameter specifications or the existence of a license statement in the spec, among other things. The <a href=""https://meta.stoplight.io/docs/spectral/9ffa04e052cc1-spectral-cli"">CLI</a> makes it easy to incorporate Spectral into both local development and CI/CD pipelines, and the <a href=""https://meta.stoplight.io/docs/spectral/eb68e7afd463e-spectral-in-java-script"">JavaScript API</a> supports more advanced use cases. The <a href=""https://github.com/stoplightio/spectral"">GitHub site</a> links to publicly available real-world rule sets from companies like Adidas, giving teams a head start on adopting their own linting rules.</p>"
Clasp;Assess;Tools;TRUE;"<p>Unfortunately, a big part of the world still runs on spreadsheets and will continue to do so. They're the ultimate tool to let anyone build those small custom tools tailored to their exact needs. However, when you want to enhance them with a level of logic that requires ""real"" code, the low-code nature of spreadsheets can then become a constraint. If you're with a company that, like Thoughtworks, uses Google's G-Suite, <strong><a href=""https://github.com/google/clasp"">Clasp</a></strong> enables you to apply at least some <a href=""/radar/techniques/continuous-delivery-cd"">Continuous Delivery</a> practices to Apps Script code. You can write the code outside of the Apps Script project, which creates options for testing, source control and build pipelines; it even lets you use <a href=""/radar/languages-and-frameworks/typescript"">TypeScript</a>. Clasp has been around for a while, and you shouldn’t expect a programming environment with all of the usual comforts, but it can greatly improve the experience of using Apps Script.</p>"
git-together;Assess;Tools;TRUE;"<p>We're always looking for ways to remove small frictions from pair programming, which is why we're excited by <a href=""https://github.com/kejadlen/git-together""><strong>git-together</strong></a>, a tool written in Rust that simplifies git commit attribution during pairing. By aliasing <code>git-together</code> as <code>git</code>, the tool allows you to add extensions to <code>git config</code> that capture committer information, aliasing each committer by their initials. Changing pairs (or switching to soloing or mob programming) requires you to run <code>git with</code>, followed by the initials of the pair (for example: <code>git with bb cc</code>), allowing you to resume your regular git workflow afterward. Every time you commit, git-together will rotate through the pair as the official author that git stores, and it will automatically add any other authors to the bottom of the commit message. The configuration can be checked in with the repo, allowing git-together to work automatically after cloning a repo.</p>"
io-ts;Adopt;languages-and-frameworks;FALSE;"<p>Our teams developing in <a href=""/radar/languages-and-frameworks/typescript"">TypeScript</a> are finding <strong><a href=""https://gcanti.github.io/io-ts/"">io-ts</a></strong> invaluable, especially when interacting with APIs that ultimately result in the creation of objects with specific types. When working with TypeScript, getting data into the bounds of the type system (i.e., from the aforementioned APIs) can lead to run-time errors that can be hard to find and debug. io-ts bridges the gap between compile-time type checking and run-time consumption of external data by providing encode and decode functions. Given the experiences of our teams and the elegance of its approach, we think io-ts is worth adopting.</p>"
Kotest;Adopt;languages-and-frameworks;FALSE;"<p><strong><a href=""https://kotest.io/"">Kotest</a></strong> (previously KotlinTest) is a stand-alone testing tool for the <a href=""/radar/languages-and-frameworks/kotlin"">Kotlin</a> ecosystem that is widely used among our teams across various Kotlin implementations — native, JVM or JavaScript. Its key advantages are that it offers a variety of testing styles in order to structure test suites and that it comes with a comprehensive set of matchers, which allow for expressive tests in an elegant internal DSL. In addition to its support for <a href=""/radar/techniques/property-based-unit-testing"">property-based testing</a>, our teams like the solid IntelliJ plugin and the support community. Many of our developers consider it their first choice and recommend those who are still using JUnit in Kotlin consider switching over to Kotest.</p>"
NestJS;Adopt;languages-and-frameworks;FALSE;"<p>In the past, we've cautioned about <a href=""/radar/platforms/node-overload"">Node overload</a>, and we're still cautious about the reasons to choose it. However, in scenarios where Node.js is required to build back-end applications, our teams are reporting that <strong><a href=""https://nestjs.com/"">NestJS</a></strong> is a suitable option to enable developers to create testable, scalable, loosely coupled and easily maintainable applications in enterprises. NestJS is a <a href=""/radar/languages-and-frameworks/typescript"">TypeScript</a>-first framework that makes the development of Node.js applications safer and less error-prone. NestJS is opinionated and comes with SOLID principles and an <a href=""/radar/languages-and-frameworks/angular"">Angular</a>-inspired architecture out of the box.</p>"
React Query;Adopt;languages-and-frameworks;FALSE;"<p><a href=""https://react-query-v3.tanstack.com/""><strong>React Query</strong></a> is often described as the missing data-fetching library for <a href=""/radar/languages-and-frameworks/react-js"">React</a>. Fetching, caching, synchronizing and updating server state is a common requirement in many React applications, and although the requirements are well understood, getting the implementation right is notoriously difficult. React Query provides a straightforward solution using hooks. It works hand-in-hand with existing async data-fetching libraries like <a href=""/radar/tools/axios"">axios</a>, <a href=""/radar/languages-and-frameworks/fetch"">Fetch</a> and <a href=""/radar/languages-and-frameworks/graphql"">GraphQL</a> since they are built on promises. As an application developer, you simply pass a function that resolves your data and leave everything else to the framework. We like that it works out of the box but still offers a lot of configuration when needed. The developer tools, unfortunately not yet available for <a href=""/radar/languages-and-frameworks/react-native"">React Native</a>, also help developers new to the framework understand how it works. For React Native, you can use a <a href=""https://github.com/bgaleotti/react-query-native-devtools"">third-party developer tools plugin</a> utilizing <a href=""/radar/tools/flipper"">Flipper</a>. In our experience, version 3 of React Query brought the stability needed to be used in production with our clients.</p>"
Gradle Kotlin DSL;Trial;languages-and-frameworks;FALSE;"<p>Previously, we blipped about the Android Gradle plugin Kotlin DSL, or <strong>Gradle Kotlin DSL</strong>, which added support for <a href=""/radar/languages-and-frameworks/kotlin"">Kotlin</a> Script as an alternative to <a href=""/radar/languages-and-frameworks/groovy"">Groovy</a> for Android projects using <a href=""/radar/tools/gradle"">Gradle</a> build scripts. The goal of replacing Groovy with Kotlin is to provide better support for refactoring and simpler editing in IDEs and, ultimately, to produce code that is easier to read and maintain. For teams already using Kotlin, it also means working on the build in a familiar language. We now suggest trialing Kotlin DSL as an alternative language to Groovy for Gradle projects in general, especially if you have large or complex Gradle build scripts. Many IDEs now include support for the migration of existing projects. Some caveats remain, and we suggest checking the <a href=""https://docs.gradle.org/current/userguide/kotlin_dsl.html"">documentation</a> for the most up-to-date details, including the prerequisites. We had a team with an at least seven-year-old, 450-line build script migrate successfully within a few days.</p>"
Cypress Component Testing;Assess;languages-and-frameworks;TRUE;"<p><a href=""https://docs.cypress.io/guides/component-testing/writing-your-first-component-test""><strong>Cypress Component Testing</strong></a> provides a testable component workbench to quickly build and test UI components. You can write component visual regression tests with the same API that you write end-to-end (E2E) UI tests. Although still in beta, component testing will be the most important feature in <a href=""/radar/tools/cypress"">Cypress</a> 10.</p>"
Podman;Adopt;Tools;FALSE;
WSL2;Adopt;Tools;FALSE;
;;;;
;;;;
;;;;
;;;;
